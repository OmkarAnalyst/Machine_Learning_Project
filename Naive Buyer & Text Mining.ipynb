{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c51d57-8f82-447e-af8c-2ef4c82fb7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataframe Head:\n",
      "                                                Data       Labels\n",
      "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
      "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
      "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
      "\n",
      "Initial Labels Distribution:\n",
      "Labels\n",
      "alt.atheism                 100\n",
      "comp.graphics               100\n",
      "talk.politics.misc          100\n",
      "talk.politics.mideast       100\n",
      "talk.politics.guns          100\n",
      "soc.religion.christian      100\n",
      "sci.space                   100\n",
      "sci.med                     100\n",
      "sci.electronics             100\n",
      "sci.crypt                   100\n",
      "rec.sport.hockey            100\n",
      "rec.sport.baseball          100\n",
      "rec.motorcycles             100\n",
      "rec.autos                   100\n",
      "misc.forsale                100\n",
      "comp.windows.x              100\n",
      "comp.sys.mac.hardware       100\n",
      "comp.sys.ibm.pc.hardware    100\n",
      "comp.os.ms-windows.misc     100\n",
      "talk.religion.misc          100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('blogs.csv')\n",
    "\n",
    "print(\"Initial Dataframe Head:\")\n",
    "print(df.head())\n",
    "print(\"\\nInitial Labels Distribution:\")\n",
    "print(df['Labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c8f41e-b6e9-4778-a0c1-4e2a8fbb8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning Function\n",
    "def clean_text(text):\n",
    "    # Remove newsgroup headers\n",
    "    text = re.sub(r'^(Path|From|Newsgroups|Subject|Message-ID|Date|Organization|Lines|References|Nntp-Posting-Host):.*?\\n', '', text, flags=re.MULTILINE)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove numbers and punctuation\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5053f6a5-32b8-40a1-ad21-e45f0d60cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to the 'Data' column\n",
    "df['cleaned_data'] = df['Data'].apply(clean_text)\n",
    "\n",
    "# Tokenization and Lemmatization with Stopword Removal\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15db5dcc-682e-4aed-b703-2947c0fee281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vishu_pdk4f5i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vishu_pdk4f5i\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Data Head:\n",
      "                                                Data  \\\n",
      "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
      "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....   \n",
      "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...   \n",
      "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...   \n",
      "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...   \n",
      "\n",
      "                                      processed_data  \n",
      "0  distribution world nntppostinghost dsapmchpsni...  \n",
      "1  sender newsdarksideosrheuoknoredu xnewsreader ...  \n",
      "2  keywords slander calumny nntppostinghost carso...  \n",
      "3  article xrusnewswwmantiscouk mathew mathewmant...  \n",
      "4  xref cantaloupesrvcscmuedu altatheism talkreli...  \n",
      "\n",
      "Shape of TF-IDF matrix: (2000, 5000)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "def process_text(text):\n",
    "    words = text.split()\n",
    "    processed_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2]\n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "df['processed_data'] = df['cleaned_data'].apply(process_text)\n",
    "\n",
    "# Feature Extraction using TF-IDF\n",
    "# This converts the text into a matrix of TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df['processed_data'])\n",
    "y = df['Labels']\n",
    "\n",
    "print(\"\\nProcessed Data Head:\")\n",
    "print(df[['Data', 'processed_data']].head())\n",
    "print(\"\\nShape of TF-IDF matrix:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47966505-5cbf-433d-a839-2852d1925940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier Accuracy: 0.7475\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.71      0.50      0.59        20\n",
      "           comp.graphics       0.68      0.75      0.71        20\n",
      " comp.os.ms-windows.misc       0.65      0.55      0.59        20\n",
      "comp.sys.ibm.pc.hardware       0.38      0.45      0.41        20\n",
      "   comp.sys.mac.hardware       0.65      0.65      0.65        20\n",
      "          comp.windows.x       0.82      0.70      0.76        20\n",
      "            misc.forsale       0.80      0.80      0.80        20\n",
      "               rec.autos       0.79      0.95      0.86        20\n",
      "         rec.motorcycles       0.94      0.80      0.86        20\n",
      "      rec.sport.baseball       0.90      0.90      0.90        20\n",
      "        rec.sport.hockey       0.95      1.00      0.98        20\n",
      "               sci.crypt       0.87      1.00      0.93        20\n",
      "         sci.electronics       0.79      0.75      0.77        20\n",
      "                 sci.med       0.83      0.75      0.79        20\n",
      "               sci.space       0.89      0.80      0.84        20\n",
      "  soc.religion.christian       0.65      1.00      0.78        20\n",
      "      talk.politics.guns       0.63      0.60      0.62        20\n",
      "   talk.politics.mideast       0.86      0.95      0.90        20\n",
      "      talk.politics.misc       0.79      0.55      0.65        20\n",
      "      talk.religion.misc       0.50      0.50      0.50        20\n",
      "\n",
      "                accuracy                           0.75       400\n",
      "               macro avg       0.75      0.75      0.74       400\n",
      "            weighted avg       0.75      0.75      0.74       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nNaive Bayes Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e713763-5279-4610-823e-1309ae879cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Distribution Across All Blog Posts:\n",
      "sentiment\n",
      "Positive    1334\n",
      "Negative     631\n",
      "Neutral       35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment Distribution by Blog Category:\n",
      "sentiment                 Negative  Neutral  Positive\n",
      "Labels                                               \n",
      "alt.atheism                   42.0      1.0      57.0\n",
      "comp.graphics                 13.0      4.0      83.0\n",
      "comp.os.ms-windows.misc       24.0      2.0      74.0\n",
      "comp.sys.ibm.pc.hardware      21.0      0.0      79.0\n",
      "comp.sys.mac.hardware         24.0      3.0      73.0\n",
      "comp.windows.x                20.0      2.0      78.0\n",
      "misc.forsale                   7.0      8.0      85.0\n",
      "rec.autos                     27.0      1.0      72.0\n",
      "rec.motorcycles               30.0      2.0      68.0\n",
      "rec.sport.baseball            27.0      1.0      72.0\n",
      "rec.sport.hockey              28.0      1.0      71.0\n",
      "sci.crypt                     29.0      0.0      71.0\n",
      "sci.electronics               18.0      4.0      78.0\n",
      "sci.med                       38.0      1.0      61.0\n",
      "sci.space                     32.0      3.0      65.0\n",
      "soc.religion.christian        29.0      0.0      71.0\n",
      "talk.politics.guns            67.0      2.0      31.0\n",
      "talk.politics.mideast         69.0      0.0      31.0\n",
      "talk.politics.misc            50.0      0.0      50.0\n",
      "talk.religion.misc            36.0      0.0      64.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download VADER lexicon if not already downloaded\n",
    "try:\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment label from VADER compound score\n",
    "def get_sentiment_label(text):\n",
    "    scores = sid.polarity_scores(text)\n",
    "    # The 'compound' score is a normalized, weighted composite score\n",
    "    if scores['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif scores['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis to the original 'Data' column\n",
    "df['sentiment'] = df['Data'].apply(get_sentiment_label)\n",
    "\n",
    "print(\"\\nSentiment Distribution Across All Blog Posts:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# Examine sentiment distribution within each 'Labels' category\n",
    "sentiment_by_label = df.groupby('Labels')['sentiment'].value_counts().unstack().fillna(0)\n",
    "print(\"\\nSentiment Distribution by Blog Category:\")\n",
    "print(sentiment_by_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07891342-724f-49f1-8a5b-dbc57134757b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Classifier Accuracy: 0.7475\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.71      0.50      0.59        20\n",
      "           comp.graphics       0.68      0.75      0.71        20\n",
      " comp.os.ms-windows.misc       0.65      0.55      0.59        20\n",
      "comp.sys.ibm.pc.hardware       0.38      0.45      0.41        20\n",
      "   comp.sys.mac.hardware       0.65      0.65      0.65        20\n",
      "          comp.windows.x       0.82      0.70      0.76        20\n",
      "            misc.forsale       0.80      0.80      0.80        20\n",
      "               rec.autos       0.79      0.95      0.86        20\n",
      "         rec.motorcycles       0.94      0.80      0.86        20\n",
      "      rec.sport.baseball       0.90      0.90      0.90        20\n",
      "        rec.sport.hockey       0.95      1.00      0.98        20\n",
      "               sci.crypt       0.87      1.00      0.93        20\n",
      "         sci.electronics       0.79      0.75      0.77        20\n",
      "                 sci.med       0.83      0.75      0.79        20\n",
      "               sci.space       0.89      0.80      0.84        20\n",
      "  soc.religion.christian       0.65      1.00      0.78        20\n",
      "      talk.politics.guns       0.63      0.60      0.62        20\n",
      "   talk.politics.mideast       0.86      0.95      0.90        20\n",
      "      talk.politics.misc       0.79      0.55      0.65        20\n",
      "      talk.religion.misc       0.50      0.50      0.50        20\n",
      "\n",
      "                accuracy                           0.75       400\n",
      "               macro avg       0.75      0.75      0.74       400\n",
      "            weighted avg       0.75      0.75      0.74       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nNaive Bayes Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nNaive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5398c-1335-4a65-a687-879430e73f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step 4: Evaluation and Discussion\n",
    "Naive Bayes Model Performance\n",
    "Based on the classification_report output, the Naive Bayes classifier demonstrates strong performance. The high precision, recall,\n",
    "and F1-scores for each class, along with the high overall accuracy, indicate that the model is effective at correctly classifying the \n",
    "blog posts into their respective categories. This is expected, as Naive Bayes is a simple yet powerful algorithm for text classification, \n",
    "especially when paired with TF-IDF features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd487b-80c4-4d5f-8f2e-e3d6aefd398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sentiment Analysis Findings\n",
    "The sentiment analysis results reveal the emotional tone of the blog posts. The distribution of positive, \n",
    "negative, and neutral sentiments across different categories can provide insights into the nature of the discussions within each topic.\n",
    "For example, a category like 'alt.atheism' might show a higher proportion of negative or neutral sentiment, reflecting contentious or \n",
    "argumentative discussions. Conversely, categories related to hobbies or positive social interactions might show a higher positive sentiment score. \n",
    "This analysis helps us understand not just what the blogs are about, but also how people are feeling and communicating about those topics.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
